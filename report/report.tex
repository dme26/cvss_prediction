
\documentclass[11pt]{article}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{fancyhdr}
\usepackage{enumitem}
\usepackage{array}
\usepackage{todonotes}
 
\pagestyle{fancy}
\fancyhf{}
\rhead{COSC480 Report} 

\lhead{Jake Norton (5695756)} 

\rfoot{\today}


\begin{document}

\noindent{\textsc{CVSS - Vulnerability Score Prediction}} \\
\noindent{
	Supervisor(s):
	David Eyers
	Veronica Liesaputra
}

\section{What are CVE and CVSS?}

\textit{The Common Vulnerabilities and Exposures (CVE) program is a dictionary or glossary of
	vulnerabilities that have been identified for specific code bases, such as software applications or
	open libraries.}[https://nvd.nist.gov/general/cve-process]

\section{Motive}
\subsection{Should we use CVSS?}

There have been a few attempts at dethroning CVSS. It does have some shortcomings:

\begin{itemize}
	\item Vaguerity
	\item Oversaturation in some scoring bands
	\item Seemingly arbitrage?/ complexity in the scoring function
	\item etc...
\end{itemize}

These being the case, would the cyber sec community use a new standard if one came along?
Historically unlikely, especially given the uptake for CVSS 4.0 is so poor.

\subsubsection{Why 4.0 is not being used}
\todo[inline]{See if there are any valid reasons why it isn't instead of just inertia}
\section{Exploration of the Space}

NVD is used by majority of studies as primary and sole data source.
Reasoning:
\begin{itemize}
	\item Data is in a nice format
	\item Largest collection of free CVE and CVSS scores, well maintained and in consistent format
\end{itemize}

Mitre is another large source.
Reasoning:
\begin{itemize}
	\item Format is more unwieldy
	\item Large lack of CVSS scores in comparison with NVD
\end{itemize}

Most other alternatives that were used in the Bayesian study have gone into archive status. There
are others however they are either pay to play VulnDB or they have a different focus, i.e
searchsploit.

\section{Analysis}

Analysis is useful in and of itself, knowing the breakdown of each metric, and the confidence there
in in relation to a prediciton will be useful. It can show shy the model may be less good at
prediction for certain metrics.

\subsection{Comparison with previous Bayesian study}

The previous analysis used bayesian techniques to compare and contrast different datasets. However,
those datasets were hard to attain, even then and were mostly webscraped. Additionally they were
using \textit{CVSS 2.0??}, where as we are now up to version 3.1.

\section{Results}
...


\subsection{Key take-aways}

Spending time with the dataset, finding its quirks, for example:

\begin{itemize}
	\item Mitre data only stores the vectors strings, but \~10 aren't in the expected format.
	\item Mitre has multiple entries for the same CVE with different scores, containing different
	      parameters. This is generally useful, but awkward when automating a training process.
\end{itemize}

\subsection{Is Mitre still useful to us?}

Yes, few possible use cases:

\begin{itemize}
	\item Use as the test data for the trained models.
\end{itemize}

This allows the model to be trained on all of NVD, but qureied on Mitre descriptions. This tests two
things... Its ability to predict based on unseen data(generalise), and an indirect similarity score.
Similarity score, insight into how different experts see the same problem.
Clustering? Look into which parts relate to what metric.



\paragraph{Aims}
\noindent
\end{document}
